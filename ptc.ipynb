{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481a837",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import os \n",
    "\n",
    "DATABASE_NAME = 'NETWORK_SECURITY'\n",
    "COLLECTION_NAME = 'NETWORK_DATA' \n",
    "MONGODB_URL = 'MONGODB_URL'\n",
    "\n",
    "ARTIFACTS_DIR = 'artifacts'\n",
    "PIPELINE_DIR = 'security'\n",
    "\n",
    "DATA_INGESTION_DIR_NAME : str = 'data_ingestion'\n",
    "DATA_INGESTION_COLLECTION_NAME: str = 'NETWORK_DATA'\n",
    "DATA_INGESTION_FEATURE_STORED_NAME:str = 'feature'\n",
    "DATA_INGESTION_INGESTED_NAME:str = 'ingested'\n",
    "DATA_INGESTION_SPLIT_RATIO:float = 0.2 \n",
    "\n",
    "RAW_DATA = 'security.csv'\n",
    "TRAIN_DATA = 'train.csv'\n",
    "TEST_DATA = 'test.csv'\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime('%m_%d_%Y_%H_%M_%S')\n",
    "\n",
    "@dataclass \n",
    "class TrainingConfiguration:\n",
    "    artifact_dir:str = ARTIFACTS_DIR \n",
    "    piprline_dir:str = PIPELINE_DIR \n",
    "    timestamp:str = TIMESTAMP \n",
    "\n",
    "trainingconfig : TrainingConfiguration=TrainingConfiguration()\n",
    "\n",
    "@dataclass \n",
    "class Data_ingestion_configeration:\n",
    "    data_ingestion_dir:str = os.path.join(trainingconfig.artifact_dir,DATA_INGESTION_DIR_NAME)\n",
    "    data_ingestion_collection:str = DATA_INGESTION_COLLECTION_NAME \n",
    "    data_ingestion_feature:str = os.path.join(data_ingestion_dir,DATA_INGESTION_FEATURE_STORED_NAME,RAW_DATA)\n",
    "    train_data_path:str = os.path.join(data_ingestion_dir,DATA_INGESTION_INGESTED_NAME,TRAIN_DATA)\n",
    "    test_data_path:str = os.path.join(data_ingestion_dir,DATA_INGESTION_INGESTED_NAME,TEST_DATA)\n",
    "    split_ratio:float = DATA_INGESTION_SPLIT_RATIO\n",
    "\n",
    "\n",
    "import pymongo \n",
    "import pandas as pd \n",
    "import certifi \n",
    "import sys\n",
    "\n",
    "\n",
    "ca = certifi()\n",
    "class MongoDBClient:\n",
    "    try:\n",
    "        def __init__(self,dt_base=DATABASE_NAME):\n",
    "            if MongoDBClient.client is None:\n",
    "                mongo_url = os.getenv(MONGODB_URL)\n",
    "                if mongo_url is None:\n",
    "                    raise Exception (f\"ERROR:-> Connection Failed\")\n",
    "            MongoDBClient.Client = pymongo.MongoClient(mongo_url,tlsCAFiles= ca)\n",
    "            self.Client=MongoDBClient.client\n",
    "            self.database = self.Client[dt_base]\n",
    "            self.database_name = dt_base\n",
    "    except Exception as e:\n",
    "        raise (e,sys)\n",
    "        \n",
    "\n",
    " \n",
    "class Network_data_collection_to_dataframe:\n",
    "    try:\n",
    "        def __init__(self):\n",
    "            self.mongodbclient = MongoDBClient()\n",
    "        def get_data(self,connection_name:str,database_name:Optional[str]=None)-> pd.DataFrame:\n",
    "            if database_name is None:\n",
    "                connection = self.mongodbclient.database[connection_name]\n",
    "            else:\n",
    "                connection = self.mongodbclient[database_name][connection_name]\n",
    "            df = pd.DataFrame(list(connection.find()))\n",
    "            if '_id' in df.columns.to_list():\n",
    "                df = df.drop('_id',axis=1)\n",
    "            df.replace({'na',np.nan},inplace=True)\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        raise (e,sys)\n",
    "\n",
    "@dataclass \n",
    "class TrainingPipelineConfig:\n",
    "    TRAIN_DATA_PATH:str = TRAIN_DATA\n",
    "    TEST_DATA:str = TEST_DATA\n",
    "\n",
    "class Data_Ingestion:\n",
    "    def __init__(self,data_ingestion_config=Data_ingestion_configeration):\n",
    "        self.data_ingestion_config = data_ingestion_config\n",
    "\n",
    "    def extract_to_feature_data(self):\n",
    "        network = Network_data_collection_to_dataframe()\n",
    "        network_data = network.get_data(self.data_ingestion_config.data_ingestion_collection)\n",
    "        feature_stored_path = self.data_ingestion_config.data_ingestion_feature\n",
    "        \n",
    "        os.makedirs(os.path.dirname(feature_stored_path),exist_ok=True)\n",
    "        network_data.to_csv(feature_stored_path,index=False,header=True)\n",
    "        return network_data\n",
    "    \n",
    "    def split_data(self,dataframe):\n",
    "        train,test = train_test_split(dataframe,test_size=self.data_ingestion_config.split_ratio)\n",
    "        # Train save\n",
    "        train_file_path = self.data_ingestion_config.train_data_path\n",
    "        os.makedirs(os.path.dirname(train_file_path), exist_ok=True)\n",
    "        train.to_csv(train_file_path, index=False, header=True)\n",
    "\n",
    "        # Test save\n",
    "        test_file_path = self.data_ingestion_config.test_data_path\n",
    "        os.makedirs(os.path.dirname(test_file_path), exist_ok=True)\n",
    "        test.to_csv(test_file_path, index=False, header=True)\n",
    "        \n",
    "\n",
    "    def init_data_ingetion(self):\n",
    "        dataframe = self.extract_to_feature_data()\n",
    "        self.split_data(dataframe)\n",
    "\n",
    "        data_pipeline_training = TrainingPipelineConfig(\n",
    "            self.data_ingestion_config.train_data_path,\n",
    "            self.data_ingestion_config.test_data_path,\n",
    "        )\n",
    "        return data_pipeline_training\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
